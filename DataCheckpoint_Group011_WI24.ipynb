{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Sheena Patel\n",
    "- Anna Chen\n",
    "- Shreya Velagala\n",
    "- Catherine Du\n",
    "- Esther Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> How does the relationship between TikTok fashion trends and their popularity as Google search terms inform the future of those trends? </b> <br>\n",
    "\n",
    "In Depth RQ: <br>\n",
    "How can we predict the level of interest in various TikTok fashion trends across New York and California using TikTok trend interest score data from January 1st, 2020 to December 31st, 2023 using a model that inputs the fashion trend name, monthly time data, and region to predict an interest rating between 0 - 100 and an associated label of 'low' (interest score < 25), 'rising' (interest score < 50), 'popular' (interest score < 75), and 'trending (interest score > 75) for the specified input in 2024? <br>\n",
    "\n",
    "This question aims to develop a predictive model that evaluates the popularity of TikTok fashion trends in different regions and times, using a quantifiable interest rating system. The focus on a state-by-state analysis allows for a detailed understanding of regional preferences and trends overtime. <br>\n",
    "\n",
    "We specifically focus on New York and California because they are the top two most populous American states and have the highest TikTok usage in the United States. When gathering data from Google Trends, we had to select states that displayed enough search queries for us to use.<br>\n",
    "\n",
    "Interest Score/Interest Over Time Definition:  <br>\n",
    "The \"interest score\" on Google Trends represents the relative popularity of a search query in a\n",
    "specific region and time frame. It is indexed from 0 to 100, where 100 signifies the peak popularity\n",
    "for the term. This score does not indicate the absolute search volume but rather shows the search term's popularity relative to the highest point on the chart for the given region and time. A higher score means more people are searching for that particular term at that time, while a lower score indicates lesser interest. The data is useful for identifying trends and understanding how interest in certain topics changes over time. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team is curious to understand how current fashion trends can be understood to predict the rating of a piece of clothing. We aim to create a prediction model that can take types of clothing and dates as input to predict the rating of a piece of clothing. We hope this model will have real-world application by possibly allowing companies to predict ratings for different clothing pieces based on GenZ fashion to potentially improve clothing purchase rates. Many datasets exist that contain information about women’s clothing including product descriptions, reviews, and ratings. However, we would like to incorporate TikTok trends into our dataset to use TikTok fashion trends as a data feature when predicting the rating for clothing. \n",
    "\n",
    "Currently, we have a few datasets including Amazon Women's Fashion Dataset<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) and Women's Ecommerce Clothing Reviews<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) that seem relevant to our project goals. Based on our initial research, our ideal dataset would include columns for clothing type, clothing description, clothing review, clothing rating, and a label for each row representing what type of TikTok trend the clothing item falls into based on the clothing description. Additionally, we found other projects that have approached similar problems. One example is this project: Amazon Women's Clothing Review<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). In the project, the researcher performs EDA by analyzing various trends in the sentiment for Amazon clothing reviews. We plan to incorporate a similar approach to our EDA by visualizing the trends in rating prediction, but analyzing prediction from the perspective of TikTok trends and views for different TikTok trends influencing rating. Another project that had a similar approach is Rating prediction<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). This project performs rating prediction similar to what we would like to do. My team plans to use this project as an example when creating our prediction model and also use a similar approach for EDA using TF-IDF to assign TikTok trends to different clothing descriptions. \n",
    "\n",
    "The first project<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) found that the main trigrams from the reviews fall into the positive sentiment categories. For instance, the research found that fit true size, run true size, fit just right, love love love, fit like glove, usual wear size, and every time wear were some of the most prominent trigrams. This research conducts more of a sentiment analysis to show that reviews and ratings are more positive in their dataset. The second project<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) performed EDA and tried to analyze what kinds of age groups make what kinds of reviews and ratings. The research project found that layering, lounge and swim clothing tend to have the best reviews. The research also interestingly found that higher age groups had worse ratings. What we found interesting about this project is that TF-IDF Vectorization was used to convert the clothing descriptions into vectors to be passed as input to the prediction model. I think we are going to have to take a similar approach to our project.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Jaewook. (2022, October 13). Amazon reviews on Women Dresses. Kaggle. https://www.kaggle.com/code/jaewook704/amazon-reviews-on-women-dresses\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Agarap, Abien Fred, and Nicapotato. (2018, Feburary 3). Women’s e-Commerce Clothing Reviews. Kaggle. https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Matteoanzano. (2023, December 5). Customer review analysis with text mining. Kaggle. https://www.kaggle.com/code/matteoanzano111/customer-review-analysis-with-text-mining/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are a few possible hypotheses under exploration:\n",
    "- TikTok trends that were more popular towards the end of quarantine (2019/2020), which we have data for, will be less popular in 2024 \n",
    "- TikTok trends that were less popular in the end of quarantine (2019/2020), which we have data for, may be more popular in 2024. \n",
    "- TikTok trends that involve more seasonal clothing like festive clothing for Christmas or summer clothing like dresses and skirts will be popular in their respective seasons in 2024. For instance, skirts which are summer clothing pieces are more likley to be popular in summer 2024, while sweaters which are winter clothing items, are more likely to be popular in winter 2024. \n",
    "    - Trends with bright colors are more likely to have higher interest scores in the summer than in other seasons. \n",
    "    - Trends with knit material will have higher interest scores in winter and cotton material will have higher interest scores in summer.\n",
    "    - Trends with more blouses will have higher interest scores in the summer and sweaters will have higher interest scores in winter. \n",
    "- TikTok trends that are considered to be the most popular of all time will continue to be very popular and have high interest scores throughout 2024. \n",
    "- TikTok trends that have been endorsed by celebrities and thus have had high interest scores in the past will continue to have high interest scores in 2024. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "We compiled a list of the top 30 TikTok trends from 1/1/2020 through 12/31/2023 using ChatGPT and external sources <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) and used Google Trends to search up these trend names and understand how the interest score rating changed overtime for them. There, we observed the data for “Interest over time”—which represents search interest (a value of 0-100 to represent peak popularity) relative to the highest point on the chart for the given region (the United States) and time (our aforementioned time frame)---where users searching for this trend name also searched with related queries. We collected 30 datasets by searching up 30 different top TikTok fashion trends on Google Trends to form our overall dataset of ~6500 datapoints. <br>\n",
    "\n",
    "\n",
    "We describe the datasets below. We will be combining all of these datasets using pd.concat and then cleaning all the merged data together. The datasets will be stacked in rows along axis = 1 and then cleaned. The code for cleaning and combining the datasets is below the dataset descriptions. We use the [Pytrends API](https://pypi.org/project/pytrends/) to gather each dataset in a for loop into a separate data structure and then combine all the datasets using a dataframe at the very end to be cleaned. <br>\n",
    "\n",
    "Data Cleaning Procedure: <br>\n",
    "The data that we began with was relatively tidy because we made sure to choose states ('CA' and 'NY) which have higher populations and higher TikTok usage so there were no null values for the interest score for the fashion trends we searched up. We initially also chose Texas as a state in our research, but Texas gave us nearly 3000 null values because the fashion trends were not searched enough within the time frame we chose to actually have interest scores on Google Trends, so we removed Texas from our analysis. We also did some pre-processing steps where for each TikTok trend we found, we searched up the keyword on Google Trends and saw whether the interest score graphs had an updward, downward, or rising and falling trend existed for the interest score on Google Trends. We removed all fashion trends that lacked a relationship between interest score overtime. We also removed all fashion trends that gave an error saying not enough values to be displayed. The main data cleaning we had to do involved merging the different datasets together and cleaning the data to be appropriate to pass into a Machine Learning model for prediction. Here are the various data cleaning steps we took: <br>\n",
    "1. Merge all 30 datasets together \n",
    "2. Use .unique() to make sure all 30 trends were added to the dataframe  \n",
    "3. Check if any null values exist, remove all data for fashion trends with null values \n",
    "4. Make sure we have >100 observations for each fashion trend, if not, expand the timeframe \n",
    "5. Rename the columns to be more clean \n",
    "6. Apply a function to make a column that transforms each interest score observation into a label: 'low', 'rising', 'popular', 'trending' so that these labels can be predicted along with the interest score \n",
    "7. Make sure labels have been assigned correctly \n",
    "8. Create a new column that converts dates to numeric months for the ML model \n",
    "9. Perform one hot encoding for the trends to be used for the ML model \n",
    "10. Remove the 'date' and 'trend' columns because they are no longer needed\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Howell, Carolyn. \"TikTok Fashion Trends 2023: Unveiling the Hottest Styles.\" High Social, 31 Aug. 2023, www.highsocial.com/resources/tiktok-fashion-trends-2023-unveiling-the-hottest-styles/.\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) \"Top TikTok Fashion Trends of 2023 (So Far).\" Sweety High, www.sweetyhigh.com/read/top-tiktok-fashion-trends-2023-040323. Accessed 23 Feb. 2024.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Dataset #1: Y2K </b><br>\n",
    "Keyword: Y2K -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023<br>\n",
    "Dataset Name: Y2K<br>\n",
    "Link to the dataset: [Google Trends Keyword Y2K](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=y2k&hl=en)<br>\n",
    "Number of observations: 209<br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))<br>\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Y2K' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #2: Cottagecore </b>\n",
    "\n",
    "Keyword: Cottagecore -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023<br>\n",
    "Dataset Name: Cottagecore<br>\n",
    "Link to the dataset: [Google Trends Keyword Cottagecore](https://www.google.com/url?q=https://trends.google.com/trends/explore?date%3D2020-01-01%25202023-12-31%26geo%3DUS%26q%3Dcottagecore%26hl%3Den&sa=D&source=docs&ust=1708745400653624&usg=AOvVaw0LOapYV77MsRKuz7RaC-Y8)<br>\n",
    "Number of observations: 209<br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Cottagecore' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #3: E-Girl </b>\n",
    "\n",
    "Keyword: E-Girl -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023<br>\n",
    "Dataset Name: E-Girl<br>\n",
    "Link to the dataset: [Google Trends Keyword E-Girl](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=e-girl&hl=en)<br>\n",
    "Number of observations: 209<br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))<br>\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'E-Girl' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #4: Vintage Thrift </b>\n",
    "\n",
    "Keyword: Vintage Thrift  -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023<br>\n",
    "Dataset Name: Vintage Thrift <br>\n",
    "Link to the dataset: [Google Trends Keyword Vintage Thrift](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=vintage%20thrift&hl=en)<br>\n",
    "Number of observations: 209<br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))<br>\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Vintage Thrift' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #5: Fairycore  </b>\n",
    "\n",
    "Keyword: Fairycore -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023<br>\n",
    "Dataset Name: Fairycore<br>\n",
    "Link to the dataset: [Google Trends Keyword Fairycore](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=fairycore&hl=en)<br>\n",
    "Number of observations: 209<br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Fairycore' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #6: Vanilla Girl </b>\n",
    "\n",
    "Keyword: Vanilla Girl -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023<br>\n",
    "Dataset Name: Vanilla Girl <br> \n",
    "Link to the dataset: [Google Trends Keyword Vanilla Girl](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=vanilla%20girl&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California)) <br>\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Vanilla Girl' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #7: Clean Girl Aesthetic </b>\n",
    "\n",
    "Keyword: Clean Girl Aesthetic -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023 <br>\n",
    "Dataset Name: Clean Girl Aesthetic <br>\n",
    "Link to the dataset: [Google Trends Keyword Clean Girl Aesthetic](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=clean%20girl%20aesthetic&hl=en)  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The dataset, sourced using Pytrends API by searching 'Clean Girl Aesthetic' on Google Trends, is formatted as a dataframe. It features metrics such as interest scores over time, including datetime, integer scores, and regional strings ('CA', 'NY'). It requires data cleaning for transforming datetime into integer month values and for the creation of trend columns using one-hot encoding. This process is vital for integrating the trends and months into a Machine Learning prediction model. Further, the interest scores will be labeled as 'low', 'rising', 'popular', or 'trending' for the model's output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #8: Blokecore  </b>\n",
    "\n",
    "Keyword: Blokecore -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Blokecore <br>\n",
    "Link to the dataset: [Google Trends Keyword Blokecore](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=clean%20girl%20aesthetic&hl=en)   <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The dataset, compiled using the Pytrends API with 'Blokecore' as the search keyword on Google Trends, is presented in a dataframe format. It includes metrics such as interest scores over time, consisting of datetime, integer scores, and regional strings ('CA', 'NY'). Necessary data cleaning involves converting datetime to integer month values and adding columns for trends via one-hot encoding. This preparation is crucial for incorporating the trends and months into a Machine Learning prediction model. Interest scores will also be classified under labels like 'low', 'rising', 'popular', or 'trending' for the model's output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #9: Barbie Challenge </b>\n",
    "\n",
    "Keyword: Barbie Challenge -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Barbie Challenge <br>\n",
    "Link to the dataset: [Google Trends Keyword Barbie Challenge](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=barbie%20challenge&hl=en)   <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: This dataset, sourced via Pytrends API with 'Barbie Challenge' from Google Trends, is in a dataframe format. It includes interest scores over time, featuring datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning involves converting datetime to integer month values and creating trend columns using one-hot encoding for integration into a Machine Learning prediction model. Interest scores are labeled as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #10: Shirt Jackets </b>\n",
    "\n",
    "Keyword: Shirt Jackets -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Shirt Jackets <br>\n",
    "Link to the dataset: [Google Trends Keyword Shirt Jackets](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=shirt%20jackets&hl=en)  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: Gathered using the Pytrends API, the 'Shirt Jackets' dataset from Google Trends is in dataframe form. It contains metrics like interest scores, datetime, integer scores, and regional strings ('CA', 'NY'). The data requires cleaning for datetime conversion into integer months and for trend columns addition via one-hot encoding, essential for Machine Learning prediction model input. Interest scores will be classified as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #11: Balletcore </b>\n",
    "\n",
    "Keyword: Balletcore -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Balletcore <br>\n",
    "Link to the dataset: [Google Trends Keyword Balletcore](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Balletcore&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Balletcore dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #12: Coastal Grandmother </b>\n",
    "\n",
    "Keyword: Coastal Grandmother -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Coastal Grandmother <br>\n",
    "Link to the dataset: [Google Trends Keyword Coastal Grandmother](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Coastal%20Grandmother&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Coastal Grandmother dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #13: Gingham </b>\n",
    "\n",
    "Keyword: Gingham -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Gingham <br>\n",
    "Link to the dataset: [Google Trends Keyword Gingham](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Gingham&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Gingham dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #14: Maxi Skirts </b>\n",
    "\n",
    "Keyword: Maxi Skirts -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Maxi Skirts <br>\n",
    "Link to the dataset: [Google Trends Keyword Maxi Skirts](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Maxi%20Skirts&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Maxi Skirts dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #15: Corset </b>\n",
    "\n",
    "Keyword: Corset  <br>\n",
    "Dataset Name: Corset <br>\n",
    "Link to the dataset: [Google Trends Keyword Corset](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Corset&hl=en)  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Corset dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #16: Leg Warmers </b>\n",
    "\n",
    "Keyword: Leg Warmers <br>\n",
    "Dataset Name: Leg Warmers <br>\n",
    "Link to the dataset: [Google Trends Keyword Leg Warmers](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Leg%20Warmers&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Leg Warmers dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #17: Birkenstocks </b>\n",
    "\n",
    "Keyword: Birkenstocks  <br>\n",
    "Dataset Name: Birkenstocks <br>\n",
    "Link to the dataset: [Google Trends Keyword Birkenstocks](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Birkenstocks&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Birkenstocks dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #18: Cloud Slides </b> <br>\n",
    "\n",
    "Keyword: Cloud Slides <br>\n",
    "Dataset Name: Cloud Slides <br>\n",
    "Link to the dataset: [Google Trends Keyword Cloud Slides](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Cloud%20Slides&hl=en) <br>\n",
    "Number of observations: 209  <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Cloud Slides dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #19: Leather </b>\n",
    "\n",
    "Keyword: Leather <br>\n",
    "Dataset Name: Leather  <br>\n",
    "Link to the dataset: [Google Trends Keyword Leather](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Leather&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Leather dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #20: Funky Pants </b>\n",
    "\n",
    "Keyword: Funky Pants <br>\n",
    "Dataset Name: Funky Pants <br>\n",
    "Link to the dataset: [Google Trends Keyword Funky Pants](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Funky%20Pants&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Funky Pants dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #21: Sweater Vests </b>\n",
    "\n",
    "Keyword: Sweater Vests <br>\n",
    "Dataset Name: Sweater Vests <br>\n",
    "Link to the dataset: [Google Trends Keyword Sweater Vests]() <br>\n",
    "Number of observations: 209  <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Sweater%20Vests&hl=enYork, California))\n",
    "\n",
    "Description: The Sweater Vests dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #22: Linen Pants </b>\n",
    "\n",
    "Keyword: Linen Pants <br>\n",
    "Dataset Name: Linen Pants <br>\n",
    "Link to the dataset: [Google Trends Keyword Linen Pants](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Linen%20Pants&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Linen Pants dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #23: Tube Tops </b>\n",
    "\n",
    "Keyword: Tube Tops <br>\n",
    "Dataset Name: Tube Tops <br>\n",
    "Link to the dataset: [Google Trends Keyword Tube Tops](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Tube%20Tops&hl=en)  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Tube Tops dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #24: Baggy pants </b>\n",
    "\n",
    "Keyword: Baggy pants <br>\n",
    "Dataset Name: Baggy pants  <br>\n",
    "Link to the dataset: [Google Trends Keyword Baggy pants](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Baggy%20pants&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Baggy pants dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #25: Low-rise </b>\n",
    "\n",
    "Keyword: Low-rise <br>\n",
    "Dataset Name: Low-rise <br> \n",
    "Link to the dataset: [Google Trends Keyword Low-rise](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Low-rise&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Low-rise dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #26: Crochet  </b>\n",
    "\n",
    "Keyword: Crochet <br>\n",
    "Dataset Name: Crochet <br>\n",
    "Link to the dataset: [Google Trends Keyword Crochet](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Crochet&hl=en) <br>\n",
    "Number of observations: 209  <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Crochet dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #27: Platform Sandals </b>\n",
    "\n",
    "Keyword: Platform Sandals <br>\n",
    "Dataset Name: Platform Sandals <br>\n",
    "Link to the dataset: [Google Trends Keyword Platform Sandals](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Platform%20Sandals&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Platform Sandals dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #28: Tomato Girl </b>\n",
    "\n",
    "Keyword: Tomato Girl <br>\n",
    "Dataset Name: Tomato Girl <br>\n",
    "Link to the dataset: [Google Trends Keyword Tomato Girl](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Tomato%20Girl&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Tomato Girl dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #29: Soft Girl Aesthetic </b>\n",
    "\n",
    "Keyword: Soft Girl Aesthetic <br>\n",
    "Dataset Name: Soft Girl Aesthetic <br>\n",
    "Link to the dataset: [Google Trends Keyword Soft Girl Aesthetic](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Soft%20Girl&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Soft Girl Aesthetic dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #30: Mermaid Core </b>\n",
    "\n",
    "Keyword: Mermaid Core <br>\n",
    "Dataset Name: Mermaid Core <br>\n",
    "Link to the dataset: [Google Trends Keyword Mermaid Core](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Mermaid%20Core&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 2 (Interest Score, Trend, 2 regions (New York, California))\n",
    "<br>\n",
    "Description: The Mermaid Core dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/GeneralMills/pytrends\n",
      "  Cloning https://github.com/GeneralMills/pytrends to /private/var/folders/g9/778rjcps4xj9l24r2094yxlw0000gn/T/pip-req-build-xob5qq9_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/GeneralMills/pytrends /private/var/folders/g9/778rjcps4xj9l24r2094yxlw0000gn/T/pip-req-build-xob5qq9_\n",
      "  Resolved https://github.com/GeneralMills/pytrends to commit a9984ffdc9b31d853dde2ab614a77ecbf2bf33a1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pytrends==4.9.2) (2.31.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pytrends==4.9.2) (2.2.0)\n",
      "Requirement already satisfied: lxml in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pytrends==4.9.2) (4.9.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends==4.9.2) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends==4.9.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends==4.9.2) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends==4.9.2) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends==4.9.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends==4.9.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends==4.9.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends==4.9.2) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends==4.9.2) (1.16.0)\n",
      "Building wheels for collected packages: pytrends\n",
      "  Building wheel for pytrends (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytrends: filename=pytrends-4.9.2-py3-none-any.whl size=15498 sha256=f2c90cfad8164a5d7f71c28b501d287d7b90eea88bca754c2433c31c23b5fd93\n",
      "  Stored in directory: /private/var/folders/g9/778rjcps4xj9l24r2094yxlw0000gn/T/pip-ephem-wheel-cache-l12tcf5g/wheels/13/84/26/5833f2738d122ee50930ffcfda6bd650564609a207ca8fa5e0\n",
      "Successfully built pytrends\n",
      "Installing collected packages: pytrends\n",
      "Successfully installed pytrends-4.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user git+https://github.com/GeneralMills/pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytrends in /Users/sheenapatel/.local/lib/python3.11/site-packages (4.9.2)\n",
      "Requirement already satisfied: requests>=2.0 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pytrends) (2.31.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pytrends) (2.2.0)\n",
      "Requirement already satisfied: lxml in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pytrends) (4.9.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->pytrends) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from requests>=2.0->pytrends) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sheenapatel/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION\n",
    "%pip install pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheenapatel/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Relevant Imports\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Top 30 TikTok trends that we will iterate through\n",
    "'''\n",
    "TikTokTrends = [\"Y2K\", \"Cottagecore\", \"E-Girl\", \"Vintage Thrift\", \"Fairycore\", \"Vanilla Girl\",\n",
    "                \"Clean Girl Aesthetic\", \"Blokecore\", \"Barbie Challenge\", \"Shirt Jackets\", \"Balletcore\",\n",
    "               \"Coastal Grandmother\", \"Gingham\", \"Maxi Skirts\", \"Corset\", \"Leg Warmers\", \"Birkenstocks\", \"Cloud Slides\",\n",
    "               \"Leather\", \"Funky Pants\", \"Sweater Vests\", \"Linen Pants\", \"Tube Tops\", \"Baggy pants\", \"Low-rise\", \"Crochet\",\n",
    "               \"Platform Sandals\", \"Tomato Girl\", \"Soft Girl Aesthetic\", \"Mermaid Core\"]\n",
    "'''\n",
    "# Multiple dataframes where one dataframe per trend will be in this list\n",
    "df_per_trend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - Baggy Pants\n",
    "df_baggy_pants = pd.read_csv('data/baggy_pants.csv')\n",
    "df_baggy_pants.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_baggy_pants['trend'] = 'Baggy pants'\n",
    "\n",
    "# 2 - Balletcore\n",
    "df_balletcore = pd.read_csv('data/balletcore.csv')\n",
    "df_balletcore.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_balletcore['trend'] = 'Balletcore'\n",
    "\n",
    "# 3 - Barbie Challenge\n",
    "df_barbie_challenge = pd.read_csv('data/barbie_challenge.csv')\n",
    "df_barbie_challenge.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_barbie_challenge['trend'] = 'Barbie Challenge'\n",
    "\n",
    "# 4 - Barbie\n",
    "df_birkenstocks = pd.read_csv('data/birkenstocks.csv')\n",
    "df_birkenstocks.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_birkenstocks['trend'] = 'Birkenstocks'\n",
    "\n",
    "# 5 - Blokecore\n",
    "df_blokecore = pd.read_csv('data/blokecore.csv')\n",
    "df_blokecore.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_blokecore['trend'] = 'Blokecore'\n",
    "\n",
    "# 6 - Clean Girl Aesthetic\n",
    "df_clean_girl_aesthetic = pd.read_csv('data/clean_girl_aesthetic.csv')\n",
    "df_clean_girl_aesthetic.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_clean_girl_aesthetic['trend'] = 'Clean Girl Aesthetic'\n",
    "\n",
    "# 7 - Cloud Slides\n",
    "df_cloud_slides = pd.read_csv('data/cloud_slides.csv')\n",
    "df_cloud_slides.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_cloud_slides['trend'] = 'Cloud Slides'\n",
    "\n",
    "# 8 - Coastal Grandmother\n",
    "df_coastal_grandmother = pd.read_csv('data/coastal_grandmother.csv')\n",
    "df_coastal_grandmother.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_coastal_grandmother['trend'] = 'Coastal Grandmother'\n",
    "\n",
    "# 9 - Corset\n",
    "df_corset = pd.read_csv('data/corset.csv')\n",
    "df_corset.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_corset['trend'] = 'Corset'\n",
    "\n",
    "# 10 - Cottagecore\n",
    "df_cottagecore = pd.read_csv('data/cottagecore.csv')\n",
    "df_cottagecore.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_cottagecore['trend'] = 'Cottagecore'\n",
    "\n",
    "# 11 - Crochet\n",
    "df_crochet = pd.read_csv('data/crochet.csv')\n",
    "df_crochet.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_crochet['trend'] = 'Crochet'\n",
    "\n",
    "# 12 - E-girl\n",
    "df_egirl = pd.read_csv('data/e-girl.csv')\n",
    "df_egirl.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_egirl['trend'] = 'E-Girl'\n",
    "\n",
    "# 13 - Fairycore\n",
    "df_fairycore = pd.read_csv('data/fairy_core.csv')\n",
    "df_fairycore.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_fairycore['trend'] = 'Fairycore'\n",
    "\n",
    "# 14 - Funky Pants\n",
    "df_funkypants = pd.read_csv('data/funky_pants.csv')\n",
    "df_funkypants.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_funkypants['trend'] = 'Funky Pants'\n",
    "\n",
    "# 15 - Ginham\n",
    "df_ginham = pd.read_csv('data/ginham.csv')\n",
    "df_ginham.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_ginham['trend'] = 'Ginham'\n",
    "\n",
    "# 16 - Leather\n",
    "df_leather = pd.read_csv('data/leather.csv')\n",
    "df_leather.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_leather['trend'] = 'Leather'\n",
    "\n",
    "# 17 - Leg Warmers\n",
    "df_leg_warmers = pd.read_csv('data/leg_warmers.csv')\n",
    "df_leg_warmers.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_leg_warmers['trend'] = 'Leg Warmers'\n",
    "\n",
    "# 18 - Linen Pants\n",
    "df_linen_pants = pd.read_csv('data/linen_pants.csv')\n",
    "df_linen_pants.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_linen_pants['trend'] = 'Linen Pants'\n",
    "\n",
    "# 19 - Low Rise\n",
    "df_low_rise = pd.read_csv('data/low-rise.csv')\n",
    "df_low_rise.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_low_rise['trend'] = 'Low-rise'\n",
    "\n",
    "# 20 - Maxi Skirts\n",
    "df_maxi_skirts = pd.read_csv('data/maxi_skirts.csv')\n",
    "df_maxi_skirts.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_maxi_skirts['trend'] = 'Maxi Skirts'\n",
    "\n",
    "# 21 - Mermaid Core\n",
    "df_mermaid_core = pd.read_csv('data/mermaid_core.csv')\n",
    "df_mermaid_core.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_mermaid_core['trend'] = 'Mermaid Core'\n",
    "\n",
    "# 22 - Platform Sandals\n",
    "df_platform_sandals = pd.read_csv('data/platform_sandals.csv')\n",
    "df_platform_sandals.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_platform_sandals['trend'] = 'Platform Sandals'\n",
    "\n",
    "# 23 - Shirt Jackets\n",
    "df_shirt_jackets = pd.read_csv('data/shirt_jackets.csv')\n",
    "df_shirt_jackets.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_shirt_jackets['trend'] = 'Shirt Jackets'\n",
    "\n",
    "# 24 - Soft Girl Aesthetic\n",
    "df_soft_girl_aesthetic = pd.read_csv('data/soft_girl_aesthetic.csv')\n",
    "df_soft_girl_aesthetic.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_soft_girl_aesthetic['trend'] = 'Soft Girl Aesthetic'\n",
    "\n",
    "# 25 - Sweater Vests\n",
    "df_sweater_vests = pd.read_csv('data/sweater_vests.csv')\n",
    "df_sweater_vests.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_sweater_vests['trend'] = 'Sweater Vests'\n",
    "\n",
    "# 26 - Tomato Girl\n",
    "df_tomato_girl = pd.read_csv('data/tomato_girl.csv')\n",
    "df_tomato_girl.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_tomato_girl['trend'] = 'Tomato Girl'\n",
    "\n",
    "# 27 - Tube Tops\n",
    "df_tube_tops = pd.read_csv('data/tube_tops.csv')\n",
    "df_tube_tops.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_tube_tops['trend'] = 'Tube Tops'\n",
    "\n",
    "# 28 - Vanilla Girl\n",
    "df_vanilla_girl = pd.read_csv('data/vanilla_girl.csv')\n",
    "df_vanilla_girl.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_vanilla_girl['trend'] = 'Vanilla Girl'\n",
    "\n",
    "# 29 - Vintage Thrift\n",
    "df_vintage_thrift = pd.read_csv('data/vintage_thirft.csv')\n",
    "df_vintage_thrift.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_vintage_thrift['trend'] = 'Vintage Thrift'\n",
    "\n",
    "# 30 - Y2K\n",
    "df_y2k = pd.read_csv('data/y2k.csv')\n",
    "df_y2k.columns = ['date', 'US-NY', 'US-CA']\n",
    "df_y2k['trend'] = 'Y2K'\n",
    "\n",
    "df_per_trend = [df_y2k, df_vintage_thrift, df_vanilla_girl, df_tube_tops,\n",
    "    df_tomato_girl, df_sweater_vests, df_soft_girl_aesthetic, df_shirt_jackets, df_platform_sandals, df_mermaid_core, df_maxi_skirts,\n",
    "    df_low_rise, df_linen_pants, df_leg_warmers, df_leather, df_ginham, df_funkypants, df_fairycore, df_egirl, df_crochet,\n",
    "    df_cottagecore, df_corset, df_coastal_grandmother, df_cloud_slides, df_clean_girl_aesthetic, df_blokecore, df_birkenstocks, df_barbie_challenge,\n",
    "    df_balletcore, df_baggy_pants]\n",
    "\n",
    "len(df_per_trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes for all trends together\n",
    "df_all_trends = pd.concat(df_per_trend, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTCA US-CA\n",
      "<class 'int'>    6270\n",
      "Name: count, dtype: int64\n",
      "DTNY US-NY\n",
      "<class 'int'>    6270\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_types_CA, data_types_NY = df_all_trends['US-CA'].apply(type).value_counts(), df_all_trends['US-NY'].apply(type).value_counts()\n",
    "print(\"DTCA\", data_types_CA)\n",
    "print(\"DTNY\", data_types_NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "na = df_all_trends['US-CA'].isna().any()\n",
    "# False\n",
    "print(na)\n",
    "na = df_all_trends['US-NY'].isna().any()\n",
    "# False\n",
    "print(na)\n",
    "print(df_all_trends['US-CA'].dtypes)\n",
    "# int64\n",
    "print(df_all_trends['US-NY'].dtypes)\n",
    "# int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US-NY</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  US-NY  US-CA trend\n",
       "0  2020-01-05     12     13   Y2K\n",
       "1  2020-01-12     13      8   Y2K\n",
       "2  2020-01-19     11     11   Y2K\n",
       "3  2020-01-26     12     10   Y2K\n",
       "4  2020-02-02     10     12   Y2K"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nY2K                     209\\nCorset                  209\\nCrochet                 209\\nLow-rise                209\\nBaggy pants             209\\nTube Tops               209\\nLinen Pants             209\\nSweater Vests           209\\nFunky Pants             209\\nLeather                 209\\nCloud Slides            209\\nBirkenstocks            209\\nLeg Warmers             209\\nMaxi Skirts             209\\nCottagecore             209\\nGingham                 209\\nCoastal Grandmother     209\\nBalletcore              209\\nShirt Jackets           209\\nBarbie Challenge        209\\nBlokecore               209\\nClean Girl Aesthetic    209\\nVanilla Girl            209\\nFairycore               209\\nVintage Thrift          209\\nE-Girl                  209\\nPlatform Sandals        209\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all_trends)\n",
    "'''\n",
    "6270\n",
    "'''\n",
    "df_all_trends[\"trend\"].value_counts()\n",
    "'''\n",
    "Y2K                     209\n",
    "Corset                  209\n",
    "Crochet                 209\n",
    "Low-rise                209\n",
    "Baggy pants             209\n",
    "Tube Tops               209\n",
    "Linen Pants             209\n",
    "Sweater Vests           209\n",
    "Funky Pants             209\n",
    "Leather                 209\n",
    "Cloud Slides            209\n",
    "Birkenstocks            209\n",
    "Leg Warmers             209\n",
    "Maxi Skirts             209\n",
    "Cottagecore             209\n",
    "Gingham                 209\n",
    "Coastal Grandmother     209\n",
    "Balletcore              209\n",
    "Shirt Jackets           209\n",
    "Barbie Challenge        209\n",
    "Blokecore               209\n",
    "Clean Girl Aesthetic    209\n",
    "Vanilla Girl            209\n",
    "Fairycore               209\n",
    "Vintage Thrift          209\n",
    "E-Girl                  209\n",
    "Platform Sandals        209\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  US-NY_Interest_Score  US-CA_Interest_Score trend\n",
       "0  2020-01-05                    12                    13   Y2K\n",
       "1  2020-01-12                    13                     8   Y2K\n",
       "2  2020-01-19                    11                    11   Y2K\n",
       "3  2020-01-26                    12                    10   Y2K\n",
       "4  2020-02-02                    10                    12   Y2K"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming Columns\n",
    "df_all_trends.rename(columns={'US-CA': 'US-CA_Interest_Score', 'US-NY': 'US-NY_Interest_Score'}, inplace=True)\n",
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning to assign labels 'low', 'rising', 'popular', and 'trending' to each datapoint.\n",
    "# This will be the output ofr the prediction\n",
    "def bin_interest_score(num):\n",
    "    if num < 25:\n",
    "        return 'low'\n",
    "    elif num < 50:\n",
    "        return 'rising'\n",
    "    elif num < 75:\n",
    "        return 'popular'\n",
    "    else:\n",
    "        return 'trending'\n",
    "\n",
    "df_all_trends['US-CA_Interest_Label'] = df_all_trends['US-CA_Interest_Score'].apply(bin_interest_score)\n",
    "df_all_trends['US-NY_Interest_Label'] = df_all_trends['US-NY_Interest_Score'].apply(bin_interest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clean Girl Aesthetic</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clean Girl Aesthetic</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clean Girl Aesthetic</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>2023-08-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clean Girl Aesthetic</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clean Girl Aesthetic</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>2023-02-05</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>Birkenstocks</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>2023-02-12</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>Birkenstocks</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>Birkenstocks</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>Birkenstocks</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>Birkenstocks</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  US-NY_Interest_Score  US-CA_Interest_Score  \\\n",
       "5200  2023-07-16                     0                     0   \n",
       "5201  2023-07-23                     0                     0   \n",
       "5202  2023-07-30                     0                     0   \n",
       "5203  2023-08-06                     0                     0   \n",
       "5204  2023-08-13                     0                     0   \n",
       "...          ...                   ...                   ...   \n",
       "5595  2023-02-05                    19                    29   \n",
       "5596  2023-02-12                    17                    28   \n",
       "5597  2023-02-19                    17                    24   \n",
       "5598  2023-02-26                    23                    23   \n",
       "5599  2023-03-05                    19                    26   \n",
       "\n",
       "                     trend US-CA_Interest_Label US-NY_Interest_Label  \n",
       "5200  Clean Girl Aesthetic                  low                  low  \n",
       "5201  Clean Girl Aesthetic                  low                  low  \n",
       "5202  Clean Girl Aesthetic                  low                  low  \n",
       "5203  Clean Girl Aesthetic                  low                  low  \n",
       "5204  Clean Girl Aesthetic                  low                  low  \n",
       "...                    ...                  ...                  ...  \n",
       "5595          Birkenstocks               rising                  low  \n",
       "5596          Birkenstocks               rising                  low  \n",
       "5597          Birkenstocks                  low                  low  \n",
       "5598          Birkenstocks                  low                  low  \n",
       "5599          Birkenstocks               rising                  low  \n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.iloc[5200:5600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  US-NY_Interest_Score  US-CA_Interest_Score trend  \\\n",
       "0 2020-01-05      1                    12                    13   Y2K   \n",
       "1 2020-01-12      1                    13                     8   Y2K   \n",
       "2 2020-01-19      1                    11                    11   Y2K   \n",
       "3 2020-01-26      1                    12                    10   Y2K   \n",
       "4 2020-02-02      2                    10                    12   Y2K   \n",
       "\n",
       "  US-CA_Interest_Label US-NY_Interest_Label  \n",
       "0                  low                  low  \n",
       "1                  low                  low  \n",
       "2                  low                  low  \n",
       "3                  low                  low  \n",
       "4                  low                  low  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the month and create a new column to be a column of numeric months\n",
    "df_all_trends['date'] = pd.to_datetime(df_all_trends['date'], format=\"mixed\")\n",
    "df_all_trends.insert(1, 'month', df_all_trends['date'].dt.month)\n",
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Trends\n",
    "TikTokTrends = [\"Y2K\", \"Cottagecore\", \"E-Girl\", \"Vintage Thrift\", \"Fairycore\", \"Vanilla Girl\",\n",
    "                \"Clean Girl Aesthetic\", \"Blokecore\", \"Barbie Challenge\", \"Shirt Jackets\", \"Balletcore\",\n",
    "               \"Coastal Grandmother\", \"Gingham\", \"Maxi Skirts\", \"Corset\", \"Leg Warmers\", \"Birkenstocks\", \"Cloud Slides\",\n",
    "               \"Leather\", \"Funky Pants\", \"Sweater Vests\", \"Linen Pants\", \"Tube Tops\", \"Baggy pants\", \"Low-rise\", \"Crochet\",\n",
    "               \"Platform Sandals\", \"Tomato Girl\", \"Soft Girl Aesthetic\", \"Mermaid Core\"]\n",
    "\n",
    "for trend in TikTokTrends:\n",
    "    df_all_trends[trend] = [1 if value == trend else 0 for value in df_all_trends['trend']]\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "      <th>Y2K</th>\n",
       "      <th>Cottagecore</th>\n",
       "      <th>E-Girl</th>\n",
       "      <th>...</th>\n",
       "      <th>Sweater Vests</th>\n",
       "      <th>Linen Pants</th>\n",
       "      <th>Tube Tops</th>\n",
       "      <th>Baggy pants</th>\n",
       "      <th>Low-rise</th>\n",
       "      <th>Crochet</th>\n",
       "      <th>Platform Sandals</th>\n",
       "      <th>Tomato Girl</th>\n",
       "      <th>Soft Girl Aesthetic</th>\n",
       "      <th>Mermaid Core</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  US-NY_Interest_Score  US-CA_Interest_Score trend  \\\n",
       "0 2020-01-05      1                    12                    13   Y2K   \n",
       "1 2020-01-12      1                    13                     8   Y2K   \n",
       "2 2020-01-19      1                    11                    11   Y2K   \n",
       "3 2020-01-26      1                    12                    10   Y2K   \n",
       "4 2020-02-02      2                    10                    12   Y2K   \n",
       "\n",
       "  US-CA_Interest_Label US-NY_Interest_Label  Y2K  Cottagecore  E-Girl  ...  \\\n",
       "0                  low                  low    1            0       0  ...   \n",
       "1                  low                  low    1            0       0  ...   \n",
       "2                  low                  low    1            0       0  ...   \n",
       "3                  low                  low    1            0       0  ...   \n",
       "4                  low                  low    1            0       0  ...   \n",
       "\n",
       "   Sweater Vests  Linen Pants  Tube Tops  Baggy pants  Low-rise  Crochet  \\\n",
       "0              0            0          0            0         0        0   \n",
       "1              0            0          0            0         0        0   \n",
       "2              0            0          0            0         0        0   \n",
       "3              0            0          0            0         0        0   \n",
       "4              0            0          0            0         0        0   \n",
       "\n",
       "   Platform Sandals  Tomato Girl  Soft Girl Aesthetic  Mermaid Core  \n",
       "0                 0            0                    0             0  \n",
       "1                 0            0                    0             0  \n",
       "2                 0            0                    0             0  \n",
       "3                 0            0                    0             0  \n",
       "4                 0            0                    0             0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'month', 'US-NY_Interest_Score', 'US-CA_Interest_Score',\n",
       "       'trend', 'US-CA_Interest_Label', 'US-NY_Interest_Label', 'Y2K',\n",
       "       'Cottagecore', 'E-Girl', 'Vintage Thrift', 'Fairycore', 'Vanilla Girl',\n",
       "       'Clean Girl Aesthetic', 'Blokecore', 'Barbie Challenge',\n",
       "       'Shirt Jackets', 'Balletcore', 'Coastal Grandmother', 'Gingham',\n",
       "       'Maxi Skirts', 'Corset', 'Leg Warmers', 'Birkenstocks', 'Cloud Slides',\n",
       "       'Leather', 'Funky Pants', 'Sweater Vests', 'Linen Pants', 'Tube Tops',\n",
       "       'Baggy pants', 'Low-rise', 'Crochet', 'Platform Sandals', 'Tomato Girl',\n",
       "       'Soft Girl Aesthetic', 'Mermaid Core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "      <th>Y2K</th>\n",
       "      <th>Cottagecore</th>\n",
       "      <th>E-Girl</th>\n",
       "      <th>Vintage Thrift</th>\n",
       "      <th>Fairycore</th>\n",
       "      <th>...</th>\n",
       "      <th>Sweater Vests</th>\n",
       "      <th>Linen Pants</th>\n",
       "      <th>Tube Tops</th>\n",
       "      <th>Baggy pants</th>\n",
       "      <th>Low-rise</th>\n",
       "      <th>Crochet</th>\n",
       "      <th>Platform Sandals</th>\n",
       "      <th>Tomato Girl</th>\n",
       "      <th>Soft Girl Aesthetic</th>\n",
       "      <th>Mermaid Core</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>trending</td>\n",
       "      <td>rising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>95</td>\n",
       "      <td>trending</td>\n",
       "      <td>rising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>77</td>\n",
       "      <td>trending</td>\n",
       "      <td>rising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>72</td>\n",
       "      <td>popular</td>\n",
       "      <td>rising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>popular</td>\n",
       "      <td>rising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6270 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  US-NY_Interest_Score  US-CA_Interest_Score US-CA_Interest_Label  \\\n",
       "0         1                    12                    13                  low   \n",
       "1         1                    13                     8                  low   \n",
       "2         1                    11                    11                  low   \n",
       "3         1                    12                    10                  low   \n",
       "4         2                    10                    12                  low   \n",
       "...     ...                   ...                   ...                  ...   \n",
       "6265     12                    39                    78             trending   \n",
       "6266     12                    46                    95             trending   \n",
       "6267     12                    40                    77             trending   \n",
       "6268     12                    34                    72              popular   \n",
       "6269     12                    41                    66              popular   \n",
       "\n",
       "     US-NY_Interest_Label  Y2K  Cottagecore  E-Girl  Vintage Thrift  \\\n",
       "0                     low    1            0       0               0   \n",
       "1                     low    1            0       0               0   \n",
       "2                     low    1            0       0               0   \n",
       "3                     low    1            0       0               0   \n",
       "4                     low    1            0       0               0   \n",
       "...                   ...  ...          ...     ...             ...   \n",
       "6265               rising    0            0       0               0   \n",
       "6266               rising    0            0       0               0   \n",
       "6267               rising    0            0       0               0   \n",
       "6268               rising    0            0       0               0   \n",
       "6269               rising    0            0       0               0   \n",
       "\n",
       "      Fairycore  ...  Sweater Vests  Linen Pants  Tube Tops  Baggy pants  \\\n",
       "0             0  ...              0            0          0            0   \n",
       "1             0  ...              0            0          0            0   \n",
       "2             0  ...              0            0          0            0   \n",
       "3             0  ...              0            0          0            0   \n",
       "4             0  ...              0            0          0            0   \n",
       "...         ...  ...            ...          ...        ...          ...   \n",
       "6265          0  ...              0            0          0            1   \n",
       "6266          0  ...              0            0          0            1   \n",
       "6267          0  ...              0            0          0            1   \n",
       "6268          0  ...              0            0          0            1   \n",
       "6269          0  ...              0            0          0            1   \n",
       "\n",
       "      Low-rise  Crochet  Platform Sandals  Tomato Girl  Soft Girl Aesthetic  \\\n",
       "0            0        0                 0            0                    0   \n",
       "1            0        0                 0            0                    0   \n",
       "2            0        0                 0            0                    0   \n",
       "3            0        0                 0            0                    0   \n",
       "4            0        0                 0            0                    0   \n",
       "...        ...      ...               ...          ...                  ...   \n",
       "6265         0        0                 0            0                    0   \n",
       "6266         0        0                 0            0                    0   \n",
       "6267         0        0                 0            0                    0   \n",
       "6268         0        0                 0            0                    0   \n",
       "6269         0        0                 0            0                    0   \n",
       "\n",
       "      Mermaid Core  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "6265             0  \n",
       "6266             0  \n",
       "6267             0  \n",
       "6268             0  \n",
       "6269             0  \n",
       "\n",
       "[6270 rows x 35 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop date and trend columns\n",
    "df_all_trends = df_all_trends.drop(['date', 'trend'], axis=1)\n",
    "df_all_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'US-NY_Interest_Score', 'US-CA_Interest_Score',\n",
       "       'US-CA_Interest_Label', 'US-NY_Interest_Label', 'Y2K', 'Cottagecore',\n",
       "       'E-Girl', 'Vintage Thrift', 'Fairycore', 'Vanilla Girl',\n",
       "       'Clean Girl Aesthetic', 'Blokecore', 'Barbie Challenge',\n",
       "       'Shirt Jackets', 'Balletcore', 'Coastal Grandmother', 'Gingham',\n",
       "       'Maxi Skirts', 'Corset', 'Leg Warmers', 'Birkenstocks', 'Cloud Slides',\n",
       "       'Leather', 'Funky Pants', 'Sweater Vests', 'Linen Pants', 'Tube Tops',\n",
       "       'Baggy pants', 'Low-rise', 'Crochet', 'Platform Sandals', 'Tomato Girl',\n",
       "       'Soft Girl Aesthetic', 'Mermaid Core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Our data from google trends doesn't contain privacy concerns for the people they collected the data from, as it is a publicly avaliable resource that does not release any info on users. However there are biases in regard to the time of the data we gathered. Though TikTok was released in 2016, the data we are utilizing is only from 2020, which would show results that are highly catered towards recent effects of TikTok, rather than its overall lifespan.\n",
    "\n",
    "Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?) How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "-  The 2 locations we are looking into are CA and NY, which both have large populations and have high Tiktok usage. It's important to recognize that our dataset represents users who actively engage with TikTok and have consistent internet access, so it does not account for places where trends have little effect. While acknowledging the influence of additional variables such as zoning and access to clothing stores on sales, we hope that our data could provide valuable suggestions for companies aiming to align their clothing offerings with popular social media trends.\n",
    "\n",
    "How will you handle issues you identified?\n",
    "- In order to handle issues related to biases and privacy in our datasets, we will emphasize that the trends we seek to predict and their impacts apply primarily to the states where this data is collected. Additionally, it may be hard to address issues of racial representation in the dataset, or biases towards specific bodies in relation to clothes trends. Although these issues may arise, our best course of action is to research and incorporate ethically sourced data. Our focus on choosing quality datasets from the start will ensure our analysis can be ethically predictive of the population.\n",
    "- For issues with locations, we want to make sure to prefaced out results with the locations we used in order to areas that are less affected by TikTok trends do not rely strongly on our results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regular meetings/checkups every Tuesday at 7pm\n",
    "* Use discord and messages as main form of communication\n",
    "* If issues with communication arises, attempt to solve them as a team\n",
    "  * If a team member is non-responsive after that, contact the professor\n",
    "* Divide up responsibilities so that everyone can contribute\n",
    "* Be open when you are struggling to complete a task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/31 | 11 AM  | N/A  | Previous Project Review | \n",
    "| 2/5  | 10 PM  | Previous Project Review | Potential Project Proposal topics | \n",
    "| 2/8  | 7  PM  | Google doc of potential topics and their relevant datasets | Choosing Project Proposal topic. Assigning roles to complete project proposals by deadline |\n",
    "| 2/16 | 2  PM  | Project Proposal | How to approach web scraping and obtaining the datasets that we need. (tiktok api) Discuss assigning roles for the implementation of the data analysis |\n",
    "| 2/21 | 5  PM  | Look into PyTrends API and google trend results from different Tiktok Trends. | Share information and create a sample dataset for 1 trend as the base for the rest of the trends. Assign each team member a role to complete Project Checkpoint #1. |\n",
    "| 2/24 | 3  PM  | Prepared clean data<br> Project Checkpoint #1: <ul><li>revise research question/report</li><li>specify the datasets we will use and why</li><li>explain our data cleaning process</li></ul> | Checkup on progress, make sure everyone is confident in their tasks |\n",
    "| 3/5  | 7  PM  | Each team member's tasks  | Checkup on progress, make sure everyone is confident in their tasks |\n",
    "| 3/12 | 7  PM  | The data prediction model is nearing conclusion, time to analyze findings | Outlining the conclusion of the project. Distributing tasks for the final project deliverable with relevant findings |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
