{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Sheena Patel\n",
    "- Anna Chen\n",
    "- Shreya Velagala\n",
    "- Catherine Du\n",
    "- Esther Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> What is the relationship between time and interest in various TikTok fashion trends? </b> <br>\n",
    "\n",
    "In Depth RQ: <br>\n",
    "How can we predict the level of interest in various TikTok fashion trends across New York, California, and Texas using TikTok trend interest score data from January 2019 to December 2023 using a model that inputs the fashion trend name, monthly time data, and region to predict an interest rating between 0 - 100 and an associated label of 'low' (interest score < 25), 'rising' (interest score < 50), 'popular' (interest score < 75), and 'trending (interest score > 75) for the specified input in 2024? <br>\n",
    "\n",
    "This question aims to develop a predictive model that evaluates the popularity of TikTok fashion trends in different regions and times, using a quantifiable interest rating system. The focus on a state-by-state analysis allows for a detailed understanding of regional preferences and trends overtime. <br>\n",
    "\n",
    "We specifically focus on New York, California, and Texas because they are the top 3 most populous states in the US and also have high TikTok usage. Additionally, using our API pytrends to collect data off of Google trends is limited in the number of search queries so we can only choose around 3 states to be represented in this research. <br>\n",
    "\n",
    "Interest Score/Interest Over Time Definition:  <br>\n",
    "The \"interest score\" on Google Trends represents the relative popularity of a search query in a\n",
    "specific region and time frame. It is indexed from 0 to 100, where 100 signifies the peak popularity\n",
    "for the term. This score does not indicate the absolute search volume but rather shows the search term's popularity relative to the highest point on the chart for the given region and time. A higher score means more people are searching for that particular term at that time, while a lower score indicates lesser interest. The data is useful for identifying trends and understanding how interest in certain topics changes over time. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team is curious to understand how current fashion trends can be understood to predict the rating of a piece of clothing. We aim to create a prediction model that can take types of clothing and dates as input to predict the rating of a piece of clothing. We hope this model will have real-world application by possibly allowing companies to predict ratings for different clothing pieces based on GenZ fashion to potentially improve clothing purchase rates. Many datasets exist that contain information about women’s clothing including product descriptions, reviews, and ratings. However, we would like to incorporate TikTok trends into our dataset to use TikTok fashion trends as a data feature when predicting the rating for clothing. \n",
    "\n",
    "Currently, we have a few datasets including Amazon Women's Fashion Dataset<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) and Women's Ecommerce Clothing Reviews<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) that seem relevant to our project goals. Based on our initial research, our ideal dataset would include columns for clothing type, clothing description, clothing review, clothing rating, and a label for each row representing what type of TikTok trend the clothing item falls into based on the clothing description. Additionally, we found other projects that have approached similar problems. One example is this project: Amazon Women's Clothing Review<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). In the project, the researcher performs EDA by analyzing various trends in the sentiment for Amazon clothing reviews. We plan to incorporate a similar approach to our EDA by visualizing the trends in rating prediction, but analyzing prediction from the perspective of TikTok trends and views for different TikTok trends influencing rating. Another project that had a similar approach is Rating prediction<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). This project performs rating prediction similar to what we would like to do. My team plans to use this project as an example when creating our prediction model and also use a similar approach for EDA using TF-IDF to assign TikTok trends to different clothing descriptions. \n",
    "\n",
    "The first project<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) found that the main trigrams from the reviews fall into the positive sentiment categories. For instance, the research found that fit true size, run true size, fit just right, love love love, fit like glove, usual wear size, and every time wear were some of the most prominent trigrams. This research conducts more of a sentiment analysis to show that reviews and ratings are more positive in their dataset. The second project<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) performed EDA and tried to analyze what kinds of age groups make what kinds of reviews and ratings. The research project found that layering, lounge and swim clothing tend to have the best reviews. The research also interestingly found that higher age groups had worse ratings. What we found interesting about this project is that TF-IDF Vectorization was used to convert the clothing descriptions into vectors to be passed as input to the prediction model. I think we are going to have to take a similar approach to our project.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Jaewook. (2022, October 13). Amazon reviews on Women Dresses. Kaggle. https://www.kaggle.com/code/jaewook704/amazon-reviews-on-women-dresses\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Agarap, Abien Fred, and Nicapotato. (2018, Feburary 3). Women’s e-Commerce Clothing Reviews. Kaggle. https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Matteoanzano. (2023, December 5). Customer review analysis with text mining. Kaggle. https://www.kaggle.com/code/matteoanzano111/customer-review-analysis-with-text-mining/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are a few possible hypotheses under exploration:\n",
    "- TikTok trends that were more popular towards the end of quarantine (2019/2020), which we have data for, will be less popular in 2024 \n",
    "- TikTok trends that were less popular in the end of quarantine (2019/2020), which we have data for, may be more popular in 2024. \n",
    "- TikTok trends that involve more seasonal clothing like festive clothing for Christmas or summer clothing like dresses and skirts will be popular in their respective seasons in 2024. For instance, skirts which are summer clothing pieces are more likley to be popular in summer 2024, while sweaters which are winter clothing items, are more likely to be popular in winter 2024. \n",
    "    - Trends with bright colors are more likely to have higher interest scores in the summer than in other seasons. \n",
    "    - Trends with knit material will have higher interest scores in winter and cotton material will have higher interest scores in summer.\n",
    "    - Trends with more blouses will have higher interest scores in the summer and sweaters will have higher interest scores in winter. \n",
    "- TikTok trends that are considered to be the most popular of all time will continue to be very popular and have high interest scores throughout 2024. \n",
    "- TikTok trends that have been endorsed by celebrities and thus have had high interest scores in the past will continue to have high interest scores in 2024. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "We compiled a list of the top 30 TikTok trends from 1/1/2020 through 12/31/2023 using ChatGPT and external sources <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) and used Google Trends to search up these trend names and understand how the interest score rating changed overtime for them. There, we observed the data for “Interest over time”—which represents search interest (a value of 0-100 to represent peak popularity) relative to the highest point on the chart for the given region (the United States) and time (our aforementioned time frame)---where users searching for this trend name also searched with related queries. We collected 30 datasets by searching up 30 different top TikTok fashion trends on Google Trends to form our overall dataset of ~6500 datapoints. <br>\n",
    "\n",
    "\n",
    "We describe the datasets below. We will be combining all of these datasets using pd.concat and then cleaning all the merged data together. The datasets will be stacked in rows along axis = 1 and then cleaned. The code for cleaning and combining the datasets is below the dataset descriptions. We use the [Pytrends API](https://pypi.org/project/pytrends/) to gather each dataset in a for loop into a separate data structure and then combine all the datasets using a dataframe at the very end to be cleaned. <br>\n",
    "\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Howell, Carolyn. \"TikTok Fashion Trends 2023: Unveiling the Hottest Styles.\" High Social, 31 Aug. 2023, www.highsocial.com/resources/tiktok-fashion-trends-2023-unveiling-the-hottest-styles/.\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) \"Top TikTok Fashion Trends of 2023 (So Far).\" Sweety High, www.sweetyhigh.com/read/top-tiktok-fashion-trends-2023-040323. Accessed 23 Feb. 2024.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Dataset #1: Y2K </b>\n",
    "Keyword: Y2K -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Y2K \n",
    "Link to the dataset: [Google Trends Keyword Y2K](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=y2k&hl=en)\n",
    "Number of observations: 209\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Y2K' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "<img src=Y2k.png width=\"300\" height=\"200\" alt=\"Interest Score Overtime on Google Trends for Y2K\">\n",
    "\n",
    "<b> Dataset #2: Cottagecore </b>\n",
    "\n",
    "Keyword: Cottagecore -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Cottagecore\n",
    "Link to the dataset: [Google Trends Keyword Cottagecore](https://www.google.com/url?q=https://trends.google.com/trends/explore?date%3D2020-01-01%25202023-12-31%26geo%3DUS%26q%3Dcottagecore%26hl%3Den&sa=D&source=docs&ust=1708745400653624&usg=AOvVaw0LOapYV77MsRKuz7RaC-Y8)\n",
    "Number of observations: 209\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Cottagecore' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "<img src=Cottagecore.png width=\"300\" height=\"200\" alt=\"Interest Score Overtime on Google Trends for Cottagecore\">\n",
    "\n",
    "<b> Dataset #3: E-Girl </b>\n",
    "\n",
    "Keyword: E-Girl -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: E-Girl\n",
    "Link to the dataset: [Google Trends Keyword E-Girl](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=e-girl&hl=en)\n",
    "Number of observations: 209\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Cottagecore' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "<img src=e-girl.png width=\"300\" height=\"200\" alt=\"Interest Score Overtime on Google Trends for Cottagecore\">\n",
    "\n",
    "<b> Dataset #4: Vintage Thrift </b>\n",
    "\n",
    "Keyword: Vintage Thrift  -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Vintage Thrift \n",
    "Link to the dataset: [Google Trends Keyword Vintage Thrift](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=vintage%20thrift&hl=en)\n",
    "Number of observations: 209\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Vintage Thrift' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "<img src=VintageThrift.png width=\"300\" height=\"200\" alt=\"Interest Score Overtime on Google Trends for Cottagecore\">\n",
    "\n",
    "<b> Dataset #5: Fairycore  </b>\n",
    "\n",
    "Keyword: Fairycore -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Fairycore\n",
    "Link to the dataset: [Google Trends Keyword Fairycore](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=fairycore&hl=en)\n",
    "Number of observations: 209\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Fairycore' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "<img src=fairycore.png width=\"300\" height=\"200\" alt=\"Interest Score Overtime on Google Trends for Cottagecore\">\n",
    "\n",
    "<b> Dataset #6: Vanilla Girl </b>\n",
    "\n",
    "Keyword: Vanilla Girl -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Vanilla Girl <br> \n",
    "Link to the dataset: [Google Trends Keyword Vanilla Girl](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=vanilla%20girl&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas)) <br>\n",
    "\n",
    "Description: The dataset, gathered using Pytrends API by searching the keyword 'Vanilla Girl' on Google Trends, is structured in a dataframe. It includes metrics like interest scores over time, with data types encompassing datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is required for converting datetime to integer month values and creating columns for trends using one-hot encoding. This preprocessing is essential for feeding the trends and months into a Machine Learning prediction model. Additionally, interest scores will be categorized into labels such as 'low', 'rising', 'popular', or 'trending' for model output. <br>\n",
    "\n",
    "<b> Dataset #7: Clean Girl Aesthetic </b>\n",
    "\n",
    "Keyword: Clean Girl Aesthetic -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023 <br>\n",
    "Dataset Name: Clean Girl Aesthetic <br>\n",
    "Link to the dataset: [Google Trends Keyword Clean Girl Aesthetic](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=clean%20girl%20aesthetic&hl=en)  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The dataset, sourced using Pytrends API by searching 'Clean Girl Aesthetic' on Google Trends, is formatted as a dataframe. It features metrics such as interest scores over time, including datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). It requires data cleaning for transforming datetime into integer month values and for the creation of trend columns using one-hot encoding. This process is vital for integrating the trends and months into a Machine Learning prediction model. Further, the interest scores will be labeled as 'low', 'rising', 'popular', or 'trending' for the model's output. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #8: Blokecore  </b>\n",
    "\n",
    "Keyword: Blokecore -> Keyword for one of the top TikTok Fashion Trends between 2019 and 2023\n",
    "Dataset Name: Blokecore <br>\n",
    "Link to the dataset: [Google Trends Keyword Blokecore](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=clean%20girl%20aesthetic&hl=en)   <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The dataset, compiled using the Pytrends API with 'Blokecore' as the search keyword on Google Trends, is presented in a dataframe format. It includes metrics such as interest scores over time, consisting of datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Necessary data cleaning involves converting datetime to integer month values and adding columns for trends via one-hot encoding. This preparation is crucial for incorporating the trends and months into a Machine Learning prediction model. Interest scores will also be classified under labels like 'low', 'rising', 'popular', or 'trending' for the model's output. <br>\n",
    "\n",
    "<b> Dataset #9: Barbie Challenge </b>\n",
    "\n",
    "Keyword: Barbie Challenge -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Barbie Challenge <br>\n",
    "Link to the dataset: [Google Trends Keyword Barbie Challenge](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=barbie%20challenge&hl=en)   <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: This dataset, sourced via Pytrends API with 'Barbie Challenge' from Google Trends, is in a dataframe format. It includes interest scores over time, featuring datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning involves converting datetime to integer month values and creating trend columns using one-hot encoding for integration into a Machine Learning prediction model. Interest scores are labeled as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #10: Shirt Jackets </b>\n",
    "\n",
    "Keyword: Shirt Jackets -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Shirt Jackets <br>\n",
    "Link to the dataset: [Google Trends Keyword Shirt Jackets](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=shirt%20jackets&hl=en)  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: Gathered using the Pytrends API, the 'Shirt Jackets' dataset from Google Trends is in dataframe form. It contains metrics like interest scores, datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). The data requires cleaning for datetime conversion into integer months and for trend columns addition via one-hot encoding, essential for Machine Learning prediction model input. Interest scores will be classified as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #11: Balletcore </b>\n",
    "\n",
    "Keyword: Balletcore -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Balletcore <br>\n",
    "Link to the dataset: [Google Trends Keyword Balletcore](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Balletcore&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Balletcore dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #12: Coastal Grandmother </b>\n",
    "\n",
    "Keyword: Coastal Grandmother -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Coastal Grandmother <br>\n",
    "Link to the dataset: [Google Trends Keyword Coastal Grandmother](https://trends.google.com/trends/explore?date=2020-01-01%202023-12-31&geo=US&q=Coastal%20Grandmother&hl=en) <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Coastal Grandmother dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #13: Gingham </b>\n",
    "\n",
    "Keyword: Gingham -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Gingham <br>\n",
    "Link to the dataset: Google Trends Keyword Gingham <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Gingham dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #14: Maxi Skirts </b>\n",
    "\n",
    "Keyword: Maxi Skirts -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Maxi Skirts <br>\n",
    "Link to the dataset: Google Trends Keyword Maxi Skirts <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Maxi Skirts dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #15: Corset </b>\n",
    "\n",
    "Keyword: Corset -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Corset <br>\n",
    "Link to the dataset: Google Trends Keyword Corset  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Corset dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #16: Leg Warmers </b>>\n",
    "\n",
    "Keyword: Leg Warmers -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Leg Warmers <br>\n",
    "Link to the dataset: Google Trends Keyword Leg Warmers <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Leg Warmers dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #17: Birkenstocks </b>>\n",
    "\n",
    "Keyword: Birkenstocks -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Birkenstocks <br>\n",
    "Link to the dataset: Google Trends Keyword Birkenstocks <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Birkenstocks dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #18: Cloud Slides </b> <br>\n",
    "\n",
    "Keyword: Cloud Slides -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Cloud Slides <br>\n",
    "Link to the dataset: Google Trends Keyword Cloud Slides <br>\n",
    "Number of observations: 209  <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Cloud Slides dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #19: Leather </b>\n",
    "\n",
    "Keyword: Leather -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Leather  <br>\n",
    "Link to the dataset: Google Trends Keyword Leather <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Leather dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #20: Funky Pants </b>\n",
    "\n",
    "Keyword: Funky Pants -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Funky Pants <br>\n",
    "Link to the dataset: Google Trends Keyword Funky Pants <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Funky Pants dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #21: Sweater Vests </b>\n",
    "\n",
    "Keyword: Sweater Vests -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Sweater Vests <br>\n",
    "Link to the dataset: Google Trends Keyword Sweater Vests <br>\n",
    "Number of observations: 209  <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Sweater Vests dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #22: Linen Pants </b>\n",
    "\n",
    "Keyword: Linen Pants -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Linen Pants <br>\n",
    "Link to the dataset: Google Trends Keyword Linen Pants <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Linen Pants dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #23: Tube Tops </b>\n",
    "\n",
    "Keyword: Tube Tops -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Tube Tops <br>\n",
    "Link to the dataset: Google Trends Keyword Tube Tops  <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Tube Tops dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #24: Baggy pants </b>\n",
    "\n",
    "Keyword: Baggy pants -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Baggy pants  <br>\n",
    "Link to the dataset: Google Trends Keyword Baggy pants <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Baggy pants dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #25: Low-rise </b>\n",
    "\n",
    "Keyword: Low-rise -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Low-rise <br> \n",
    "Link to the dataset: Google Trends Keyword Low-rise <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Low-rise dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #26: Crochet  </b>\n",
    "\n",
    "Keyword: Crochet -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Crochet <br>\n",
    "Link to the dataset: Google Trends Keyword Crochet <br>\n",
    "Number of observations: 209  <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Crochet dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #27: Platform Sandals </b>\n",
    "\n",
    "Keyword: Platform Sandals -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Platform Sandals <br>\n",
    "Link to the dataset: Google Trends Keyword Platform Sandals <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Platform Sandals dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "\n",
    "<b> Dataset #28: Tomato Girl </b>\n",
    "\n",
    "Keyword: Tomato Girl -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Tomato Girl <br>\n",
    "Link to the dataset: Google Trends Keyword Tomato Girl <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Tomato Girl dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #28: Soft Girl Aesthetic </b>\n",
    "\n",
    "Keyword: Soft Girl Aesthetic -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Soft Girl Aesthetic <br>\n",
    "Link to the dataset: Google Trends Keyword Soft Girl Aesthetic <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Soft Girl Aesthetic dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>\n",
    "\n",
    "<b> Dataset #29 : Mermaid Core </b>\n",
    "\n",
    "Keyword: Mermaid Core -> Top TikTok Fashion Trend between 2019 and 2023 <br>\n",
    "Dataset Name: Mermaid Core <br>\n",
    "Link to the dataset: Google Trends Keyword Mermaid Core <br>\n",
    "Number of observations: 209 <br>\n",
    "Number of variables: 3 (Interest Score, Trend, 3 regions (New York, California, and Texas))\n",
    "Description: The Mermaid Core dataset, obtained through Pytrends API from Google Trends, is structured in a dataframe. It tracks interest scores over time and includes datetime, integer scores, and regional strings ('TX', 'CA', 'NY'). Data cleaning is necessary to transform datetime into integer months and to create trend-specific columns through one-hot encoding. This process aids in preparing the data for a Machine Learning prediction model. Interest scores are to be categorized as 'low', 'rising', 'popular', or 'trending'. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytrends\n",
      "  Downloading pytrends-4.9.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytrends) (2.28.2)\n",
      "Collecting lxml\n",
      "  Downloading lxml-5.1.0-cp310-cp310-macosx_10_9_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytrends) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shrey/Library/Python/3.10/lib/python/site-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=0.25->pytrends) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=0.25->pytrends) (2022.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.0->pytrends) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.0->pytrends) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.0->pytrends) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.0->pytrends) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shrey/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.1->pandas>=0.25->pytrends) (1.16.0)\n",
      "Installing collected packages: lxml, pytrends\n",
      "Successfully installed lxml-5.1.0 pytrends-4.9.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION\n",
    "%pip install pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Imports\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Top 30 TikTok trends that we will iterate through\n",
    "TikTokTrends = [\"Y2K\", \"Cottagecore\", \"E-Girl\", \"Vintage Thrift\", \"Fairycore\", \"Vanilla Girl\",\n",
    "                \"Clean Girl Aesthetic\", \"Blokecore\", \"Barbie Challenge\", \"Shirt Jackets\", \"Balletcore\",\n",
    "               \"Coastal Grandmother\", \"Gingham\", \"Maxi Skirts\", \"Corset\", \"Leg Warmers\", \"Birkenstocks\", \"Cloud Slides\",\n",
    "               \"Leather\", \"Funky Pants\", \"Sweater Vests\", \"Linen Pants\", \"Tube Tops\", \"Baggy pants\", \"Low-rise\", \"Crochet\",\n",
    "               \"Platform Sandals\", \"Tomato Girl\", \"Soft Girl Aesthetic\", \"Mermaid Core\"]\n",
    "# Multiple dataframes where one dataframe per trend will be in this list\n",
    "df_per_trend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y2K']\n",
      "['Cottagecore']\n",
      "['E-Girl']\n",
      "['Vintage Thrift']\n",
      "['Fairycore']\n",
      "['Vanilla Girl']\n",
      "['Clean Girl Aesthetic']\n",
      "['Blokecore']\n",
      "['Barbie Challenge']\n",
      "['Shirt Jackets']\n",
      "['Balletcore']\n",
      "['Coastal Grandmother']\n",
      "['Gingham']\n",
      "['Maxi Skirts']\n",
      "['Corset']\n",
      "['Leg Warmers']\n",
      "['Birkenstocks']\n",
      "['Cloud Slides']\n",
      "['Leather']\n",
      "['Funky Pants']\n",
      "['Sweater Vests']\n",
      "['Linen Pants']\n",
      "['Tube Tops']\n",
      "['Baggy pants']\n",
      "['Low-rise']\n",
      "['Crochet']\n",
      "['Platform Sandals']\n",
      "['Tomato Girl']\n",
      "['Soft Girl Aesthetic']\n",
      "['Mermaid Core']\n"
     ]
    }
   ],
   "source": [
    "# For loop that iterates through all top 27 TikTok Trends from 2020 to 2023 and populates a\n",
    "# list (df_per_trend) with interest scores for each trend.\n",
    "for trend in TikTokTrends:\n",
    "    # google trends df\n",
    "    # Initialize pytrends\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "    # Define the keyword and timeframe\n",
    "    kw_list = []\n",
    "    kw_list.append(trend)\n",
    "    print(kw_list)\n",
    "    timeframe = '2020-01-01 2023-12-31'\n",
    "\n",
    "    # Define geographic locations\n",
    "    geo_locations = ['US-CA', 'US-TX', 'US-NY']  # California, Texas, New York, DEFAULT (ALL of US when state not specified)\n",
    "\n",
    "    # Dictionary to hold data\n",
    "    trends_data = {}\n",
    "\n",
    "    # Fetching the data for each location\n",
    "    for geo in geo_locations:\n",
    "        pytrends.build_payload(kw_list, cat=0, timeframe=timeframe, geo=geo, gprop='')\n",
    "        data = pytrends.interest_over_time()\n",
    "        if not data.empty:\n",
    "            trends_data[geo] = data[trend]\n",
    "\n",
    "    # Combine data from different regions into one DataFrame\n",
    "    df_curr_trend = pd.concat(trends_data, axis=1)\n",
    "\n",
    "    df_curr_trend = df_curr_trend.reset_index()\n",
    "    df_curr_trend[\"trend\"] = trend\n",
    "    df_per_trend.append(df_curr_trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes for all trends together\n",
    "df_all_trends = pd.concat(df_per_trend, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>US-TX</th>\n",
       "      <th>US-NY</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  US-CA  US-TX  US-NY trend\n",
       "0 2020-01-05     13   17.0     17   Y2K\n",
       "1 2020-01-12     15   15.0     12   Y2K\n",
       "2 2020-01-19     11   14.0     15   Y2K\n",
       "3 2020-01-26      9   14.0     17   Y2K\n",
       "4 2020-02-02      8    9.0     20   Y2K"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nY2K                     209\\nCorset                  209\\nCrochet                 209\\nLow-rise                209\\nBaggy pants             209\\nTube Tops               209\\nLinen Pants             209\\nSweater Vests           209\\nFunky Pants             209\\nLeather                 209\\nCloud Slides            209\\nBirkenstocks            209\\nLeg Warmers             209\\nMaxi Skirts             209\\nCottagecore             209\\nGingham                 209\\nCoastal Grandmother     209\\nBalletcore              209\\nShirt Jackets           209\\nBarbie Challenge        209\\nBlokecore               209\\nClean Girl Aesthetic    209\\nVanilla Girl            209\\nFairycore               209\\nVintage Thrift          209\\nE-Girl                  209\\nPlatform Sandals        209\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all_trends)\n",
    "'''\n",
    "5643\n",
    "'''\n",
    "df_all_trends[\"trend\"].value_counts()\n",
    "'''\n",
    "Y2K                     209\n",
    "Corset                  209\n",
    "Crochet                 209\n",
    "Low-rise                209\n",
    "Baggy pants             209\n",
    "Tube Tops               209\n",
    "Linen Pants             209\n",
    "Sweater Vests           209\n",
    "Funky Pants             209\n",
    "Leather                 209\n",
    "Cloud Slides            209\n",
    "Birkenstocks            209\n",
    "Leg Warmers             209\n",
    "Maxi Skirts             209\n",
    "Cottagecore             209\n",
    "Gingham                 209\n",
    "Coastal Grandmother     209\n",
    "Balletcore              209\n",
    "Shirt Jackets           209\n",
    "Barbie Challenge        209\n",
    "Blokecore               209\n",
    "Clean Girl Aesthetic    209\n",
    "Vanilla Girl            209\n",
    "Fairycore               209\n",
    "Vintage Thrift          209\n",
    "E-Girl                  209\n",
    "Platform Sandals        209\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>US-TX_Interest_Score</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Y2K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  US-CA_Interest_Score  US-TX_Interest_Score  \\\n",
       "0 2020-01-05                    13                  17.0   \n",
       "1 2020-01-12                    15                  15.0   \n",
       "2 2020-01-19                    11                  14.0   \n",
       "3 2020-01-26                     9                  14.0   \n",
       "4 2020-02-02                     8                   9.0   \n",
       "\n",
       "   US-NY_Interest_Score trend  \n",
       "0                    17   Y2K  \n",
       "1                    12   Y2K  \n",
       "2                    15   Y2K  \n",
       "3                    17   Y2K  \n",
       "4                    20   Y2K  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming Columns\n",
    "df_all_trends.rename(columns={'US-CA': 'US-CA_Interest_Score',\n",
    "                   'US-TX': 'US-TX_Interest_Score', 'US-NY': 'US-NY_Interest_Score'}, inplace=True)\n",
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning to assign labels 'low', 'rising', 'popular', and 'trending' to each datapoint.\n",
    "# This will be the output ofr the prediction\n",
    "def bin_interest_score(num):\n",
    "    if num < 25:\n",
    "        return 'low'\n",
    "    elif num < 50:\n",
    "        return 'rising'\n",
    "    elif num < 75:\n",
    "        return 'popular'\n",
    "    else:\n",
    "        return 'trending'\n",
    "\n",
    "df_all_trends['US-CA_Interest_Label'] = df_all_trends['US-CA_Interest_Score'].apply(bin_interest_score)\n",
    "df_all_trends['US-TX_Interest_Label'] = df_all_trends['US-TX_Interest_Score'].apply(bin_interest_score)\n",
    "df_all_trends['US-NY_Interest_Label'] = df_all_trends['US-NY_Interest_Score'].apply(bin_interest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>US-TX_Interest_Score</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-TX_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>32</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Low-rise</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low-rise</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Low-rise</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>2023-08-06</td>\n",
       "      <td>82</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low-rise</td>\n",
       "      <td>trending</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Low-rise</td>\n",
       "      <td>rising</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>2023-02-05</td>\n",
       "      <td>29</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33</td>\n",
       "      <td>Platform Sandals</td>\n",
       "      <td>rising</td>\n",
       "      <td>rising</td>\n",
       "      <td>rising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>2023-02-12</td>\n",
       "      <td>42</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28</td>\n",
       "      <td>Platform Sandals</td>\n",
       "      <td>rising</td>\n",
       "      <td>rising</td>\n",
       "      <td>rising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>45</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Platform Sandals</td>\n",
       "      <td>rising</td>\n",
       "      <td>popular</td>\n",
       "      <td>rising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>34</td>\n",
       "      <td>60.0</td>\n",
       "      <td>57</td>\n",
       "      <td>Platform Sandals</td>\n",
       "      <td>rising</td>\n",
       "      <td>popular</td>\n",
       "      <td>popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>45</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44</td>\n",
       "      <td>Platform Sandals</td>\n",
       "      <td>rising</td>\n",
       "      <td>popular</td>\n",
       "      <td>rising</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  US-CA_Interest_Score  US-TX_Interest_Score  \\\n",
       "5200 2023-07-16                    32                  23.0   \n",
       "5201 2023-07-23                     0                   0.0   \n",
       "5202 2023-07-30                    33                   0.0   \n",
       "5203 2023-08-06                    82                  19.0   \n",
       "5204 2023-08-13                    26                   0.0   \n",
       "...         ...                   ...                   ...   \n",
       "5595 2023-02-05                    29                  30.0   \n",
       "5596 2023-02-12                    42                  35.0   \n",
       "5597 2023-02-19                    45                  57.0   \n",
       "5598 2023-02-26                    34                  60.0   \n",
       "5599 2023-03-05                    45                  63.0   \n",
       "\n",
       "      US-NY_Interest_Score             trend US-CA_Interest_Label  \\\n",
       "5200                    13          Low-rise               rising   \n",
       "5201                     0          Low-rise                  low   \n",
       "5202                    16          Low-rise               rising   \n",
       "5203                     0          Low-rise             trending   \n",
       "5204                    13          Low-rise               rising   \n",
       "...                    ...               ...                  ...   \n",
       "5595                    33  Platform Sandals               rising   \n",
       "5596                    28  Platform Sandals               rising   \n",
       "5597                    38  Platform Sandals               rising   \n",
       "5598                    57  Platform Sandals               rising   \n",
       "5599                    44  Platform Sandals               rising   \n",
       "\n",
       "     US-TX_Interest_Label US-NY_Interest_Label  \n",
       "5200                  low                  low  \n",
       "5201                  low                  low  \n",
       "5202                  low                  low  \n",
       "5203                  low                  low  \n",
       "5204                  low                  low  \n",
       "...                   ...                  ...  \n",
       "5595               rising               rising  \n",
       "5596               rising               rising  \n",
       "5597              popular               rising  \n",
       "5598              popular              popular  \n",
       "5599              popular               rising  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.iloc[5200:5600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>US-TX_Interest_Score</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-TX_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  US-CA_Interest_Score  US-TX_Interest_Score  \\\n",
       "0 2020-01-05      1                    13                  17.0   \n",
       "1 2020-01-12      1                    15                  15.0   \n",
       "2 2020-01-19      1                    11                  14.0   \n",
       "3 2020-01-26      1                     9                  14.0   \n",
       "4 2020-02-02      2                     8                   9.0   \n",
       "\n",
       "   US-NY_Interest_Score trend US-CA_Interest_Label US-TX_Interest_Label  \\\n",
       "0                    17   Y2K                  low                  low   \n",
       "1                    12   Y2K                  low                  low   \n",
       "2                    15   Y2K                  low                  low   \n",
       "3                    17   Y2K                  low                  low   \n",
       "4                    20   Y2K                  low                  low   \n",
       "\n",
       "  US-NY_Interest_Label  \n",
       "0                  low  \n",
       "1                  low  \n",
       "2                  low  \n",
       "3                  low  \n",
       "4                  low  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the month and create a new column to be a column of numeric months\n",
    "df_all_trends['date'] = pd.to_datetime(df_all_trends['date'])\n",
    "df_all_trends.insert(1, 'month', df_all_trends['date'].dt.month)\n",
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for Trends\n",
    "TikTokTrends = [\"Y2K\", \"Cottagecore\", \"E-Girl\", \"Vintage Thrift\", \"Fairycore\", \"Vanilla Girl\",\n",
    "                \"Clean Girl Aesthetic\", \"Blokecore\", \"Barbie Challenge\", \"Shirt Jackets\", \"Balletcore\",\n",
    "               \"Coastal Grandmother\", \"Gingham\", \"Maxi Skirts\", \"Corset\", \"Leg Warmers\", \"Birkenstocks\", \"Cloud Slides\",\n",
    "               \"Leather\", \"Funky Pants\", \"Sweater Vests\", \"Linen Pants\", \"Tube Tops\", \"Baggy pants\", \"Low-rise\", \"Crochet\",\n",
    "               \"Platform Sandals\", \"Tomato Girl\", \"Soft Girl Aesthetic\", \"Mermaid Core\"]\n",
    "\n",
    "for trend in TikTokTrends:\n",
    "    df_all_trends[trend] = [1 if value == trend else 0 for value in df_all_trends['trend']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>US-CA_Interest_Score</th>\n",
       "      <th>US-TX_Interest_Score</th>\n",
       "      <th>US-NY_Interest_Score</th>\n",
       "      <th>trend</th>\n",
       "      <th>US-CA_Interest_Label</th>\n",
       "      <th>US-TX_Interest_Label</th>\n",
       "      <th>US-NY_Interest_Label</th>\n",
       "      <th>Y2K</th>\n",
       "      <th>...</th>\n",
       "      <th>Sweater Vests</th>\n",
       "      <th>Linen Pants</th>\n",
       "      <th>Tube Tops</th>\n",
       "      <th>Baggy pants</th>\n",
       "      <th>Low-rise</th>\n",
       "      <th>Crochet</th>\n",
       "      <th>Platform Sandals</th>\n",
       "      <th>Tomato Girl</th>\n",
       "      <th>Soft Girl Aesthetic</th>\n",
       "      <th>Mermaid Core</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Y2K</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  US-CA_Interest_Score  US-TX_Interest_Score  \\\n",
       "0 2020-01-05      1                    13                  17.0   \n",
       "1 2020-01-12      1                    15                  15.0   \n",
       "2 2020-01-19      1                    11                  14.0   \n",
       "3 2020-01-26      1                     9                  14.0   \n",
       "4 2020-02-02      2                     8                   9.0   \n",
       "\n",
       "   US-NY_Interest_Score trend US-CA_Interest_Label US-TX_Interest_Label  \\\n",
       "0                    17   Y2K                  low                  low   \n",
       "1                    12   Y2K                  low                  low   \n",
       "2                    15   Y2K                  low                  low   \n",
       "3                    17   Y2K                  low                  low   \n",
       "4                    20   Y2K                  low                  low   \n",
       "\n",
       "  US-NY_Interest_Label  Y2K  ...  Sweater Vests  Linen Pants  Tube Tops  \\\n",
       "0                  low    1  ...              0            0          0   \n",
       "1                  low    1  ...              0            0          0   \n",
       "2                  low    1  ...              0            0          0   \n",
       "3                  low    1  ...              0            0          0   \n",
       "4                  low    1  ...              0            0          0   \n",
       "\n",
       "   Baggy pants  Low-rise  Crochet  Platform Sandals  Tomato Girl  \\\n",
       "0            0         0        0                 0            0   \n",
       "1            0         0        0                 0            0   \n",
       "2            0         0        0                 0            0   \n",
       "3            0         0        0                 0            0   \n",
       "4            0         0        0                 0            0   \n",
       "\n",
       "   Soft Girl Aesthetic  Mermaid Core  \n",
       "0                    0             0  \n",
       "1                    0             0  \n",
       "2                    0             0  \n",
       "3                    0             0  \n",
       "4                    0             0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'month', 'US-CA_Interest_Score', 'US-TX_Interest_Score',\n",
       "       'US-NY_Interest_Score', 'trend', 'US-CA_Interest_Label',\n",
       "       'US-TX_Interest_Label', 'US-NY_Interest_Label', 'Y2K', 'Cottagecore',\n",
       "       'E-Girl', 'Vintage Thrift', 'Fairycore', 'Vanilla Girl',\n",
       "       'Clean Girl Aesthetic', 'Blokecore', 'Barbie Challenge',\n",
       "       'Shirt Jackets', 'Balletcore', 'Coastal Grandmother', 'Gingham',\n",
       "       'Maxi Skirts', 'Corset', 'Leg Warmers', 'Birkenstocks', 'Cloud Slides',\n",
       "       'Leather', 'Funky Pants', 'Sweater Vests', 'Linen Pants', 'Tube Tops',\n",
       "       'Baggy pants', 'Low-rise', 'Crochet', 'Platform Sandals', 'Tomato Girl',\n",
       "       'Soft Girl Aesthetic', 'Mermaid Core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date and trend columns\n",
    "df_all_trends = df_all_trends.drop(['date', 'trend'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'US-CA_Interest_Score', 'US-TX_Interest_Score',\n",
       "       'US-NY_Interest_Score', 'US-CA_Interest_Label', 'US-TX_Interest_Label',\n",
       "       'US-NY_Interest_Label', 'Y2K', 'Cottagecore', 'E-Girl',\n",
       "       'Vintage Thrift', 'Fairycore', 'Vanilla Girl', 'Clean Girl Aesthetic',\n",
       "       'Blokecore', 'Barbie Challenge', 'Shirt Jackets', 'Balletcore',\n",
       "       'Coastal Grandmother', 'Gingham', 'Maxi Skirts', 'Corset',\n",
       "       'Leg Warmers', 'Birkenstocks', 'Cloud Slides', 'Leather', 'Funky Pants',\n",
       "       'Sweater Vests', 'Linen Pants', 'Tube Tops', 'Baggy pants', 'Low-rise',\n",
       "       'Crochet', 'Platform Sandals', 'Tomato Girl', 'Soft Girl Aesthetic',\n",
       "       'Mermaid Core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trends.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin Analysis (Iron Man; Thor) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
